{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "585834bb",
   "metadata": {},
   "source": [
    "### First try for linear probes: \n",
    "\n",
    "- Global probe (z_H) is_solved accuracy: 1.0000\n",
    "- Local probe (z_L) per_cell_correct accuracy: 0.9998\n",
    "- Saved trained probes to results/probes\n",
    "\n",
    "\n",
    "-- Something could be going wrong, or it's strong evidence that z_h encodes global features and z_l encodes local ones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250dd4a0",
   "metadata": {},
   "source": [
    "### Second try for linear probes (switching z_l and z_h): \n",
    "\n",
    "python scripts/train_linear_probes.py --probes_dir results/probes --use_global_z z_L --use_local_z z_H\n",
    "\n",
    "- Global probe (z_L) is_solved accuracy: 1.0000\n",
    "- Local probe (z_H) per_cell_correct accuracy: 0.9660"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4615dd3",
   "metadata": {},
   "source": [
    "python scripts/train_linear_probes.py --probes_dir results/probes\n",
    "Global probe (z_H) is_solved accuracy: 1.0000\n",
    "Local probe (z_L) per_cell_correct accuracy: 0.9128\n",
    "Saved trained probes to results/probes\n",
    "(.venv) ubuntu@leo-vm2:~/HRM$ python scripts/train_linear_probes.py --probes_dir results/probes --use_global_z z_L --use_local_z z_H\n",
    "Global probe (z_L) is_solved accuracy: 1.0000\n",
    "Local probe (z_H) per_cell_correct accuracy: 0.8991\n",
    "Saved trained probes to results/probes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2668bb",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5449fd8d",
   "metadata": {},
   "source": [
    "### Additional Probe Metrics and Why They Matter\n",
    "\n",
    "We'll evaluate more than raw accuracy to understand how well hidden-state probes capture signal and how reliable their scores are across steps and representations:\n",
    "- Precision/Recall/F1: balance performance under class imbalance and error costs.\n",
    "- Confusion Matrix: error types (false positives vs false negatives).\n",
    "- Calibration (Reliability) Curve: do probe probabilities reflect true likelihoods?\n",
    "- Threshold Sweep: sensitivity to decision boundary; find optimal operating point.\n",
    "- Per-Step Curves: how information emerges across ACT steps.\n",
    "- z_H vs z_L Comparison: which level encodes global vs local signals more linearly.\n",
    "- Per-Puzzle Aggregation: consistency across puzzles (variance, outliers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8364b5db",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'results/probes/probe_global.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m index_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(probes_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprobe_index.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Load probe datasets\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m global_samples \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mglobal_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m local_samples \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(local_path)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(index_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[0;32m~/HRM/.venv/lib/python3.10/site-packages/torch/serialization.py:1484\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1481\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m   1482\u001b[0m     pickle_load_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1484\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m   1485\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m   1486\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m   1487\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m   1488\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m   1489\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/HRM/.venv/lib/python3.10/site-packages/torch/serialization.py:759\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    757\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer: FileLike, mode: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _opener[IO[\u001b[38;5;28mbytes\u001b[39m]]:\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 759\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    760\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    761\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/HRM/.venv/lib/python3.10/site-packages/torch/serialization.py:740\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: Union[\u001b[38;5;28mstr\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike[\u001b[38;5;28mstr\u001b[39m]], mode: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 740\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'results/probes/probe_global.pt'"
     ]
    }
   ],
   "source": [
    "# Utilities to load probe datasets and trained probes, then compute metrics\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Paths\n",
    "probes_dir = os.path.join(\"results\", \"probes\")\n",
    "global_path = os.path.join(probes_dir, \"probe_global.pt\")\n",
    "local_path = os.path.join(probes_dir, \"probe_local.pt\")\n",
    "index_path = os.path.join(probes_dir, \"probe_index.json\")\n",
    "\n",
    "# Load probe datasets\n",
    "global_samples = torch.load(global_path)\n",
    "local_samples = torch.load(local_path)\n",
    "with open(index_path, \"r\") as f:\n",
    "    probe_index = json.load(f)\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + torch.exp(-x))\n",
    "\n",
    "def metrics_binary(logits: torch.Tensor, y: torch.Tensor, threshold: float = 0.5):\n",
    "    probs = sigmoid(logits)\n",
    "    preds = (probs >= threshold).to(torch.int64)\n",
    "    y = y.to(torch.int64)\n",
    "    tp = int(((preds == 1) & (y == 1)).sum().item())\n",
    "    tn = int(((preds == 0) & (y == 0)).sum().item())\n",
    "    fp = int(((preds == 1) & (y == 0)).sum().item())\n",
    "    fn = int(((preds == 0) & (y == 1)).sum().item())\n",
    "    acc = (tp + tn) / max(1, tp + tn + fp + fn)\n",
    "    prec = tp / max(1, tp + fp)\n",
    "    rec = tp / max(1, tp + fn)\n",
    "    f1 = 2 * prec * rec / max(1e-8, prec + rec)\n",
    "    return {\n",
    "        \"acc\": acc,\n",
    "        \"precision\": prec,\n",
    "        \"recall\": rec,\n",
    "        \"f1\": f1,\n",
    "        \"tp\": tp,\n",
    "        \"tn\": tn,\n",
    "        \"fp\": fp,\n",
    "        \"fn\": fn,\n",
    "        \"probs\": probs.detach(),\n",
    "    }\n",
    "\n",
    "def calibration_bins(probs: torch.Tensor, y: torch.Tensor, n_bins: int = 10):\n",
    "    # Returns per-bin avg prob and accuracy\n",
    "    probs = probs.detach().cpu().numpy()\n",
    "    y = y.detach().cpu().numpy()\n",
    "    bins = np.linspace(0.0, 1.0, n_bins + 1)\n",
    "    bin_ids = np.digitize(probs, bins) - 1\n",
    "    out = []\n",
    "    for b in range(n_bins):\n",
    "        m = bin_ids == b\n",
    "        if m.sum() == 0:\n",
    "            out.append((bins[b:b+2].mean(), np.nan, 0))\n",
    "        else:\n",
    "            out.append((probs[m].mean(), y[m].mean(), int(m.sum())))\n",
    "    return out  # list of (avg_prob, avg_acc, count)\n",
    "\n",
    "def load_trained_probe(path: str, in_dim: int):\n",
    "    # A simple Linear(D,1); we only need weights to compute logits: x @ W^T + b\n",
    "    sd = torch.load(path)\n",
    "    W = sd.get('linear.weight')\n",
    "    b = sd.get('linear.bias')\n",
    "    if W is None:\n",
    "        # For safety, try alternative keys\n",
    "        for k in sd:\n",
    "            if k.endswith('weight') and sd[k].shape == (1, in_dim):\n",
    "                W = sd[k]\n",
    "            if k.endswith('bias') and sd[k].shape == (1,):\n",
    "                b = sd[k]\n",
    "    assert W is not None and b is not None, \"Invalid probe state dict\"\n",
    "    return W.detach(), b.detach()\n",
    "\n",
    "def build_global_dataset(samples, use_z: str = 'z_H'):\n",
    "    X, y, steps = [], [], []\n",
    "    for row in samples:\n",
    "        z = row[use_z]  # [B, D]\n",
    "        labels = row.get('labels', {})\n",
    "        is_solved = labels.get('is_solved')\n",
    "        if z is None or is_solved is None:\n",
    "            continue\n",
    "        # Aggregate batch to single vector and label for the entry\n",
    "        z_vec = z.mean(dim=0)  # [D]\n",
    "        if is_solved.ndim > 0:\n",
    "            y_scalar = (is_solved.float().mean() > 0.5).to(torch.int64)\n",
    "        else:\n",
    "            y_scalar = is_solved.to(torch.int64)\n",
    "        X.append(z_vec.float())\n",
    "        y.append(y_scalar)\n",
    "        steps.append(int(row.get('step', 0)))\n",
    "    X = torch.stack(X)\n",
    "    y = torch.stack(y)\n",
    "    steps = torch.tensor(steps)\n",
    "    return X, y, steps\n",
    "\n",
    "def build_local_dataset(samples, use_z: str = 'z_L'):\n",
    "    X, y, steps = [], [], []\n",
    "    for row in samples:\n",
    "        z = row[use_z]  # [B, T, D] or [T, D]\n",
    "        labels = row.get('labels', {})\n",
    "        pc = labels.get('per_cell_correct')  # [B, T] or [T]\n",
    "        if z is None or pc is None:\n",
    "            continue\n",
    "        if z.ndim == 3:\n",
    "            B, T, D = z.shape\n",
    "            X.append(z.reshape(B * T, D).float())\n",
    "            y.append(pc.reshape(-1).to(torch.int64))\n",
    "        else:\n",
    "            T, D = z.shape\n",
    "            X.append(z.reshape(T, D).float())\n",
    "            y.append(pc.reshape(-1).to(torch.int64))\n",
    "        steps.append(int(row.get('step', 0)))\n",
    "    X = torch.cat(X, dim=0)\n",
    "    y = torch.cat(y, dim=0)\n",
    "    steps = torch.tensor(steps)\n",
    "    return X, y, steps\n",
    "\n",
    "# Build datasets for z_H and z_L\n",
    "Xg_H, yg, steps_g = build_global_dataset(global_samples, use_z='z_H')\n",
    "Xg_L, _ygL, _steps_gL = build_global_dataset(global_samples, use_z='z_L')\n",
    "Xl_H, yl_H, steps_lH = build_local_dataset(local_samples, use_z='z_H')\n",
    "Xl_L, yl_L, steps_lL = build_local_dataset(local_samples, use_z='z_L')\n",
    "\n",
    "# Load trained probes if present\n",
    "gp_H_path = os.path.join(probes_dir, 'global_probe_z_H.pt')\n",
    "gp_L_path = os.path.join(probes_dir, 'global_probe_z_L.pt')\n",
    "lp_H_path = os.path.join(probes_dir, 'local_probe_z_H.pt')\n",
    "lp_L_path = os.path.join(probes_dir, 'local_probe_z_L.pt')\n",
    "\n",
    "def probe_logits(X: torch.Tensor, W: torch.Tensor, b: torch.Tensor):\n",
    "    return (X @ W.t()) + b  # [N,1]\n",
    "\n",
    "results = {}\n",
    "# Global z_H\n",
    "if os.path.exists(gp_H_path):\n",
    "    W, b = load_trained_probe(gp_H_path, Xg_H.shape[1])\n",
    "    logits = probe_logits(Xg_H, W, b).view(-1)\n",
    "    results['global_z_H'] = metrics_binary(logits, yg)\n",
    "\n",
    "# Global z_L\n",
    "if os.path.exists(gp_L_path):\n",
    "    W, b = load_trained_probe(gp_L_path, Xg_L.shape[1])\n",
    "    logits = probe_logits(Xg_L, W, b).view(-1)\n",
    "    # Use yg for comparison (same entries aggregated); approximate\n",
    "    results['global_z_L'] = metrics_binary(logits, yg)\n",
    "\n",
    "# Local z_H\n",
    "if os.path.exists(lp_H_path):\n",
    "    W, b = load_trained_probe(lp_H_path, Xl_H.shape[1])\n",
    "    logits = probe_logits(Xl_H, W, b).view(-1)\n",
    "    results['local_z_H'] = metrics_binary(logits, yl_H)\n",
    "\n",
    "# Local z_L\n",
    "if os.path.exists(lp_L_path):\n",
    "    W, b = load_trained_probe(lp_L_path, Xl_L.shape[1])\n",
    "    logits = probe_logits(Xl_L, W, b).view(-1)\n",
    "    results['local_z_L'] = metrics_binary(logits, yl_L)\n",
    "\n",
    "# Print summary metrics\n",
    "for k, m in results.items():\n",
    "    print(f\"{k}: acc={m['acc']:.4f} precision={m['precision']:.4f} recall={m['recall']:.4f} f1={m['f1']:.4f} TP={m['tp']} TN={m['tn']} FP={m['fp']} FN={m['fn']}\")\n",
    "\n",
    "# Calibration summary (bin means)\n",
    "for k, m in results.items():\n",
    "    bins = calibration_bins(m['probs'], (m['probs'] >= 0.5).to(torch.int64))\n",
    "    # Note: using predicted positives for quick visualization of reliability; for true calibration use y\n",
    "    print(f\"\\nCalibration (rough, by predicted positive) for {k}:\")\n",
    "    for avg_p, avg_acc, count in bins:\n",
    "        print(f\"  bin_avg_p={avg_p:.3f} acc={avg_acc if not np.isnan(avg_acc) else 'nan'} count={count}\")\n",
    "\n",
    "# Threshold sweep to see operating point sensitivity\n",
    "\n",
    "def threshold_sweep(logits: torch.Tensor, y: torch.Tensor, steps=11):\n",
    "    ts = np.linspace(0.0, 1.0, steps)\n",
    "    out = []\n",
    "    for t in ts:\n",
    "        m = metrics_binary(logits, y, threshold=t)\n",
    "        out.append((t, m['acc'], m['precision'], m['recall'], m['f1']))\n",
    "    return out\n",
    "\n",
    "for k, m in list(results.items()):\n",
    "    # Recover logits approximately via logit(p)\n",
    "    probs = m['probs']\n",
    "    logits = torch.log(probs / (1 - probs + 1e-8))\n",
    "    print(f\"\\nThreshold sweep for {k} (t, acc, prec, rec, f1):\")\n",
    "    for row in threshold_sweep(logits, (probs >= 0.5).to(torch.int64)):\n",
    "        print(\"  \", tuple(round(v, 4) if isinstance(v, float) else v for v in row))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed41b8da",
   "metadata": {},
   "source": [
    "### Interpreting These Metrics\n",
    "\n",
    "- Precision/Recall/F1: Accuracy alone can hide class imbalance. Precision penalizes false positives (claiming solved/correct when not), recall penalizes false negatives (missing solved/correct). F1 balances both.\n",
    "- Confusion Matrix: Helps diagnose whether the probe tends to over/under-predict; useful for adjusting thresholds in downstream use.\n",
    "- Calibration Curve: If the probe outputs are well-calibrated, a 0.8 probability should correspond to ~80% correctness. Poor calibration suggests scores are not reliable as probabilities.\n",
    "- Threshold Sweep: Shows robustness of decisions to the chosen cutoff; helpful when the application has asymmetric costs or requires high precision/recall.\n",
    "- Per-Step Dynamics: In ACT models, signal should strengthen over steps; plotting accuracy vs step reveals when representations become linearly separable.\n",
    "- z_H vs z_L: Validates representational roles â€” global status tends to be in z_H, local correctness in z_L. If this flips, it informs architecture/training changes.\n",
    "- Per-Puzzle Aggregation: High variance across puzzles suggests brittleness; consistent performance indicates generalizable encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bc3fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Per-step accuracy curves (requires mapping entries to steps)\n",
    "# For global probes, we approximated aggregation per entry; here, we compute per-step slices using the step metadata.\n",
    "\n",
    "def per_step_accuracy_global(samples, use_z: str, probe_path: str):\n",
    "    X, y, steps = build_global_dataset(samples, use_z=use_z)\n",
    "    if not os.path.exists(probe_path):\n",
    "        print(f\"Missing probe {probe_path}\")\n",
    "        return []\n",
    "    W, b = load_trained_probe(probe_path, X.shape[1])\n",
    "    logits = probe_logits(X, W, b).view(-1)\n",
    "    probs = sigmoid(logits)\n",
    "    preds = (probs >= 0.5).to(torch.int64)\n",
    "    out = []\n",
    "    for s in sorted(set(steps.tolist())):\n",
    "        m = steps == s\n",
    "        if m.sum() == 0:\n",
    "            continue\n",
    "        acc = (preds[m] == y[m]).float().mean().item()\n",
    "        out.append((s, acc))\n",
    "    return out\n",
    "\n",
    "gH_steps = per_step_accuracy_global(global_samples, 'z_H', gp_H_path)\n",
    "gL_steps = per_step_accuracy_global(global_samples, 'z_L', gp_L_path)\n",
    "print(\"Per-step global accuracy (z_H):\", gH_steps)\n",
    "print(\"Per-step global accuracy (z_L):\", gL_steps)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
